error_vec<-c()
for (id in 1:8){
########## selecting predictors ###########
models <- summary(best_fit)$which[id,-1]       ### id variables is for the number of predictors
predictors <- names(which(models == TRUE))
predictors <- paste(predictors, collapse = "+")
model.formula<-as.formula(paste0("lpsa", "~", predictors))
##### 5 fold cv #######
set.seed(1)
train.control <- trainControl(method = "cv", number = 5)
cv <- train(model.formula, data = mydata, method = "lm",
trControl = train.control)
cv$results$RMSE
error_vec<-c(error_vec,cv$results$RMSE)
}
which.min(error_vec)
error_vec
library(ElemStatLearn)
mydata=prostate
mydata$train<-NULL
library(caret)
set.seed(1)
train=sample(1:nrow(mydata),0.8*nrow(mydata))
Y.train<-mydata$lpsa[train]
Y.test=mydata$lpsa[-train]
X.train=mydata[train,1:2]
X.test=mydata[-train,1:2]
training = mydata[train, 1:9]
testing = mydata[-train, 1:9]
library(leaps)
best_subset<-regsubsets(lpsa~.,data=training,method = "exhaustive",nvmax=8)
best_summary<-summary(best_subset)
which.min(best_summary$cp)
which.min(best_summary$bic)
cp_min<-which.min(best_summary$cp)
bic_min<-which.min(best_summary$bic)
best_summary$outmat[cp_min,]
best_summary$cp
cp_set<-best_summary$outmat[cp_min,]
cp_pred <- names(which(cp_set == "*"))
cp_pred <- paste(cp_pred, collapse = "+")
cp.formula<-as.formula(paste0("lpsa", "~", cp_pred))
cp_model<-lm(cp.formula,data = training)
cp_pred_err<-predict(cp_model,testing)
cp_pred_err
View(mydata)
difference_cp<-cp_pred_err-testing$lpsa
testerror<-mean(difference_cp^2)
testerror
bic_set<-best_summary$outmat[bic_min,]
bic_pred <- names(which(bic_set == "*"))
bic_pred <- paste(bic_pred, collapse = "+")
bic.formula<-as.formula(paste0("lpsa", "~", bic_pred))
bic_model<-lm(bic.formula,data = training)
bic_pred_err<-predict(bic_model,testing)
difference_bic<-bic_pred_err-testing$lpsa
testerror_bic<-mean(difference_bic^2)
testerror_bic
library("rpart")
library(MASS)
wine_data = read.csv('wine.data.txt',header = FALSE)
summary(wine_data)
str(wine_data)
wine_data$V1<-as.factor(wine_data$V1)
train = sample(1:nrow(wine_data), nrow(wine_data)*0.80)
wine_train_data = wine_data[train, ]
wine_test_data = wine_data[-train, ]
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
wine_model <- rpart(V1~., data = wine_train_data, method = "class", control = model.control)
summary(wine_model)
names(wine_model)
wine_model$variable.importance
train_pred = predict(wine_model, wine_train_data, type = "class")
test_pred = predict(wine_model, wine_test_data, type = "class")
mean(test_pred != wine_test_data$V1)
summary(train_pred)
summary(test_pred)
## dendograms ###
x11()
plot(wine_model,uniform = T,compress = T,margin = 0.2,main="Full Tree")
text(wine_model,use.n=T,all=T,cex=1)
#### Pruning for better performance ####
wine_model$cptable[,4]
# 4th column of the cp table to get cross validation error
x11()
plot(wine_model$cptable[,4],main="Cp for model selection",ylab="cv error")
min_cp = which.min(wine_model$cptable[,4])
wine_model_pruned <- prune(wine_model, cp = wine_model$cptable[min_cp,1])
x11()
plot(wine_model_pruned,uniform = T,compress = T,margin = 0.2,main="Pruned Tree")
text(wine_model_pruned,use.n=T,all=T,cex=1)
test_pred_prune = predict(wine_model_pruned, wine_test_data, type = "class")
mean(test_pred_prune != wine_test_data$V1)
summary(test_pred_prune)
difference_prune<-as.numeric(test_pred_prune)-as.numeric(wine_test_data$V1)
testerror<-mean(difference_prune^2)
wine_data = read.csv('wine.data.txt',header = FALSE)
wine_data = read.text('wine.data.txt',header = FALSE)
setwd("C:/Users/Jaideep/Desktop/UB Data Science/Sem 1/R.Hageman/hw4")
library("rpart")
library(MASS)
wine_data = read.text('wine.data.txt',header = FALSE)
summary(wine_data)
str(wine_data)
wine_data$V1<-as.factor(wine_data$V1)
train = sample(1:nrow(wine_data), nrow(wine_data)*0.80)
wine_train_data = wine_data[train, ]
wine_test_data = wine_data[-train, ]
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
wine_model <- rpart(V1~., data = wine_train_data, method = "class", control = model.control)
summary(wine_model)
names(wine_model)
wine_model$variable.importance
train_pred = predict(wine_model, wine_train_data, type = "class")
test_pred = predict(wine_model, wine_test_data, type = "class")
mean(test_pred != wine_test_data$V1)
summary(train_pred)
summary(test_pred)
## dendograms ###
x11()
plot(wine_model,uniform = T,compress = T,margin = 0.2,main="Full Tree")
text(wine_model,use.n=T,all=T,cex=1)
#### Pruning for better performance ####
wine_model$cptable[,4]
# 4th column of the cp table to get cross validation error
x11()
plot(wine_model$cptable[,4],main="Cp for model selection",ylab="cv error")
min_cp = which.min(wine_model$cptable[,4])
wine_model_pruned <- prune(wine_model, cp = wine_model$cptable[min_cp,1])
x11()
plot(wine_model_pruned,uniform = T,compress = T,margin = 0.2,main="Pruned Tree")
text(wine_model_pruned,use.n=T,all=T,cex=1)
test_pred_prune = predict(wine_model_pruned, wine_test_data, type = "class")
mean(test_pred_prune != wine_test_data$V1)
summary(test_pred_prune)
difference_prune<-as.numeric(test_pred_prune)-as.numeric(wine_test_data$V1)
testerror<-mean(difference_prune^2)
wine_data = read.csv('wine.data.txt',header = FALSE)
summary(wine_data)
str(wine_data)
wine_data$V1<-as.factor(wine_data$V1)
train = sample(1:nrow(wine_data), nrow(wine_data)*0.80)
wine_train_data = wine_data[train, ]
wine_test_data = wine_data[-train, ]
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
wine_model <- rpart(V1~., data = wine_train_data, method = "class", control = model.control)
summary(wine_model)
names(wine_model)
wine_model$variable.importance
train_pred = predict(wine_model, wine_train_data, type = "class")
test_pred = predict(wine_model, wine_test_data, type = "class")
mean(test_pred != wine_test_data$V1)
summary(train_pred)
summary(test_pred)
## dendograms ###
x11()
plot(wine_model,uniform = T,compress = T,margin = 0.2,main="Full Tree")
text(wine_model,use.n=T,all=T,cex=1)
#### Pruning for better performance ####
wine_model$cptable[,4]
# 4th column of the cp table to get cross validation error
x11()
plot(wine_model$cptable[,4],main="Cp for model selection",ylab="cv error")
min_cp = which.min(wine_model$cptable[,4])
wine_model_pruned <- prune(wine_model, cp = wine_model$cptable[min_cp,1])
x11()
plot(wine_model_pruned,uniform = T,compress = T,margin = 0.2,main="Pruned Tree")
text(wine_model_pruned,use.n=T,all=T,cex=1)
test_pred_prune = predict(wine_model_pruned, wine_test_data, type = "class")
mean(test_pred_prune != wine_test_data$V1)
summary(test_pred_prune)
difference_prune<-as.numeric(test_pred_prune)-as.numeric(wine_test_data$V1)
testerror<-mean(difference_prune^2)
which.min(wine_model$cptable[,4])
wine_model$cptable
wine_data = read.csv('wine.data.txt',header = FALSE)
summary(wine_data)
str(wine_data)
wine_data$V1<-as.factor(wine_data$V1)
set.seed(12345)
train = sample(1:nrow(wine_data), nrow(wine_data)*0.80)
wine_train_data = wine_data[train, ]
wine_test_data = wine_data[-train, ]
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
wine_model <- rpart(V1~., data = wine_train_data, method = "class", control = model.control)
summary(wine_model)
names(wine_model)
wine_model$variable.importance
train_pred = predict(wine_model, wine_train_data, type = "class")
test_pred = predict(wine_model, wine_test_data, type = "class")
mean(test_pred != wine_test_data$V1)
summary(train_pred)
summary(test_pred)
## dendograms ###
x11()
plot(wine_model,uniform = T,compress = T,margin = 0.2,main="Full Tree")
text(wine_model,use.n=T,all=T,cex=1)
#### Pruning for better performance ####
wine_model$cptable[,4]
# 4th column of the cp table to get cross validation error
x11()
plot(wine_model$cptable[,4],main="Cp for model selection",ylab="cv error")
min_cp = which.min(wine_model$cptable[,4])  ## taking the model whose Cp corresponds to minimum cross val error
wine_model_pruned <- prune(wine_model, cp = wine_model$cptable[min_cp,1])
x11()
plot(wine_model_pruned,uniform = T,compress = T,margin = 0.2,main="Pruned Tree")
text(wine_model_pruned,use.n=T,all=T,cex=1)
test_pred_prune = predict(wine_model_pruned, wine_test_data, type = "class")
mean(test_pred_prune != wine_test_data$V1)
summary(test_pred_prune)
difference_prune<-as.numeric(test_pred_prune)-as.numeric(wine_test_data$V1)
testerror<-mean(difference_prune^2)
testerror
wine_data = read.csv('wine.data.txt',header = FALSE)
summary(wine_data)
str(wine_data)
wine_data$V1<-as.factor(wine_data$V1)
set.seed(123)
train = sample(1:nrow(wine_data), nrow(wine_data)*0.80)
wine_train_data = wine_data[train, ]
wine_test_data = wine_data[-train, ]
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
wine_model <- rpart(V1~., data = wine_train_data, method = "class", control = model.control)
summary(wine_model)
names(wine_model)
wine_model$variable.importance
train_pred = predict(wine_model, wine_train_data, type = "class")
test_pred = predict(wine_model, wine_test_data, type = "class")
mean(test_pred != wine_test_data$V1)
summary(train_pred)
summary(test_pred)
## dendograms ###
x11()
plot(wine_model,uniform = T,compress = T,margin = 0.2,main="Full Tree")
text(wine_model,use.n=T,all=T,cex=1)
#### Pruning for better performance ####
wine_model$cptable[,4]
# 4th column of the cp table to get cross validation error
x11()
plot(wine_model$cptable[,4],main="Cp for model selection",ylab="cv error")
min_cp = which.min(wine_model$cptable[,4])  ## taking the model whose Cp corresponds to minimum cross val error
wine_model_pruned <- prune(wine_model, cp = wine_model$cptable[min_cp,1])
x11()
plot(wine_model_pruned,uniform = T,compress = T,margin = 0.2,main="Pruned Tree")
text(wine_model_pruned,use.n=T,all=T,cex=1)
test_pred_prune = predict(wine_model_pruned, wine_test_data, type = "class")
mean(test_pred_prune != wine_test_data$V1)
summary(test_pred_prune)
wine_data = read.csv('wine.data.txt',header = FALSE)
summary(wine_data)
str(wine_data)
wine_data$V1<-as.factor(wine_data$V1)
set.seed(100)
train = sample(1:nrow(wine_data), nrow(wine_data)*0.80)
wine_train_data = wine_data[train, ]
wine_test_data = wine_data[-train, ]
model.control <- rpart.control(minsplit = 5, xval = 10, cp = 0)
wine_model <- rpart(V1~., data = wine_train_data, method = "class", control = model.control)
summary(wine_model)
names(wine_model)
wine_model$variable.importance
train_pred = predict(wine_model, wine_train_data, type = "class")
test_pred = predict(wine_model, wine_test_data, type = "class")
mean(test_pred != wine_test_data$V1)
summary(train_pred)
summary(test_pred)
## dendograms ###
x11()
plot(wine_model,uniform = T,compress = T,margin = 0.2,main="Full Tree")
text(wine_model,use.n=T,all=T,cex=1)
#### Pruning for better performance ####
wine_model$cptable[,4]
# 4th column of the cp table to get cross validation error
x11()
plot(wine_model$cptable[,4],main="Cp for model selection",ylab="cv error")
min_cp = which.min(wine_model$cptable[,4])  ## taking the model whose Cp corresponds to minimum cross val error
wine_model_pruned <- prune(wine_model, cp = wine_model$cptable[min_cp,1])
x11()
plot(wine_model_pruned,uniform = T,compress = T,margin = 0.2,main="Pruned Tree")
text(wine_model_pruned,use.n=T,all=T,cex=1)
test_pred_prune = predict(wine_model_pruned, wine_test_data, type = "class")
mean(test_pred_prune != wine_test_data$V1)
summary(test_pred_prune)
difference_prune<-as.numeric(test_pred_prune)-as.numeric(wine_test_data$V1)
testerror<-mean(difference_prune^2)
x11()
plot(wine_model$cptable[,4],main="Cp for model selection",ylab="cv error")
min_cp
wine_model$frame
wine_model$where
trainingnodes <- rownames(wine_model$frame)[wine_model$where]
trainingnodes
test_pred
summary(wine_model$where)
str(wine_model$where)
str(as.factor(wine_model$where))
summary(as.factor(wine_model$where))
summary(as.factor(wine_model_pruned$where))
test_pred_prune
summary(test_pred_prune)
nodes_wine <- wine_model_pruned
nodes_wine <- wine_model_pruned
nodes_wine$frame$yval = as.numeric(rownames(nodes_wine$frame))
testnodes <- predict(nodes_wine, wine_test_data, type="vector")
testnodes
summary(as.factor(wine_model$where))
wine_model$where
summary(as.factor(testnodes))
wine_model_pruned$where
summary(as.factor(wine_model_pruned$where))
testnodes
wine_model_pruned$where
as.factor(wine_model_pruned$where)
wine_model_pruned$frame
wine_model_pruned$where
summary(as.factor(wine_model_pruned$where))
testnodes
summary(as.factor(testnodes))
## train prediction ##
train_pred_prune = predict(wine_model_pruned, wine_train_data, type = "class")
mean(train_pred_prune != wine_train_data$V1)
nodes_wine <- wine_model_pruned
nodes_wine$frame$yval = as.numeric(rownames(nodes_wine$frame))
trainnodes <- predict(nodes_wine, wine_train_data, type="vector")
trainnodes
summary(as.factor(trainnodes))
nodes_wine <- wine_model_pruned
nodes_wine$frame$yval = as.numeric(rownames(nodes_wine$frame))
testnodes <- predict(nodes_wine, wine_test_data, type="vector")
testnodes
summary(as.factor(testnodes))
mydata<-read.csv("diabetes.csv")
colnames(mydata)
colnames(mydata)
library(caret)
library(rpart)
library(gbm)
#install.packages("randomForest")
library(randomForest)
#library(geneplotter)
library(ISLR)
str(mydata)
mydata$Outcome<-as.factor(mydata$Outcome)
train<-sample(1:nrow(mydata),0.8*nrow(mydata))
traindata<-mydata[train,]
testdata<-mydata[-train,]
y_true<-as.factor(testdata$Outcome)
y_true<-as.numeric(y_true)-1
log.fit<-glm(Outcome~.,data = traindata,family = 'binomial')
summary(log.fit)
log_pred_test<-predict(log.fit,newdata = test_nopred,type = 'response')
log_pred_test<-predict(log.fit,newdata = testdata,type = 'response')
log_pred_test[which(log_pred_test>0.5)]=1
log_pred_test[which(log_pred_test<=0.5)]=0
y_test<-as.numeric(testdata$crim_med)-1
test_err_log<-sum(abs(log_pred_test-y_test))/length(y_test)
test_err_log
log_pred_test
log.fit<-glm(Outcome~.,data = traindata,family = 'binomial')
log_pred_test<-predict(log.fit,newdata = testdata,type = 'response')
log_pred_test
log_pred_test[which(log_pred_test>0.5)]=1
log_pred_test[which(log_pred_test<=0.5)]=0
log_pred_test
y_true<-as.factor(testdata$Outcome)
y_true<-as.numeric(y_true)-1
test_err_log<-sum(abs(log_pred_test-y_true))/length(y_true)
test_err_log
mydata<-read.csv("diabetes.csv")
colnames(mydata)
#install.packages("gbm")
library(caret)
library(rpart)
library(gbm)
#install.packages("randomForest")
library(randomForest)
#library(geneplotter)
library(ISLR)
str(mydata)
mydata$Outcome<-as.factor(mydata$Outcome)
train<-sample(1:nrow(mydata),0.8*nrow(mydata))
traindata<-mydata[train,]
testdata<-mydata[-train,]
y_true<-as.factor(testdata$Outcome)
y_true<-as.numeric(y_true)-1
#### randomForest ####
rf.fit<-randomForest(Outcome~.,data=traindata,n.tree=10000)
x11()
varImpPlot(rf.fit)
importance(rf.fit)
y_hat<-predict(rf.fit,newdata = testdata,type = "response")
confusionMatrix(y_hat,testdata$Outcome)
## 77.27 % accuracy
y_hat<-as.numeric(y_hat)-1
misclass_rf<-sum(abs(y_hat-y_true))/length(y_true)
misclass_rf
#### bagging #####
bag.fit<-randomForest(Outcome~.,data=traindata,n.tree=10000,mtry=8)
x11()
varImpPlot(bag.fit)
importance(bag.fit)
y_hat<-predict(bag.fit,newdata = testdata,type = "response")
confusionMatrix(y_hat,testdata$Outcome)
## 74.68 % accuracy ##
y_hat<-as.numeric(y_hat)-1
misclass_bag<-sum(abs(y_hat-y_true))/length(y_true)
### boosting ####
boost.train<-traindata
boost.train$Outcome<-as.numeric(traindata$Outcome)-1
boost.test<-testdata
boost.test$Outcome<-as.numeric(testdata$Outcome)-1
boost.fit<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.1,interaction.depth = 5,distribution = "adaboost")
boost.fit2<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.6,interaction.depth = 5,distribution = "adaboost")
names(boost.fit)
summary(boost.fit)
y_hat<-predict(boost.fit,newdata = boost.test,n.trees = 100,type = "response")
y_hat1<-predict(boost.fit2,newdata = boost.test,n.trees = 100,type = "response")
misclass_boost<-sum(abs(y_hat-y_true))/length(y_true)
## logistic Regression ##
log.fit<-glm(Outcome~.,data = traindata,family = 'binomial')
summary(log.fit)
log_pred_test<-predict(log.fit,newdata = testdata,type = 'response')
log_pred_test[which(log_pred_test>0.5)]=1
log_pred_test[which(log_pred_test<=0.5)]=0
test_err_log<-sum(abs(log_pred_test-y_true))/length(y_true)
misclass_rf
misclass_bag
misclass_boost
test_err_log
x11()
varImpPlot(rf.fit)
importance(rf.fit)
misclass_rf
#### bagging #####
bag.fit<-randomForest(Outcome~.,data=traindata,n.tree=10000,mtry=8)
x11()
varImpPlot(bag.fit)
importance(bag.fit)
y_hat<-predict(bag.fit,newdata = testdata,type = "response")
y_hat<-as.numeric(y_hat)-1
misclass_bag<-sum(abs(y_hat-y_true))/length(y_true)
misclass_bag
boost.train<-traindata
boost.train$Outcome<-as.numeric(traindata$Outcome)-1
boost.test<-testdata
boost.test$Outcome<-as.numeric(testdata$Outcome)-1
boost.fit<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.1,interaction.depth = 5,distribution = "adaboost")
names(boost.fit)
summary(boost.fit)
y_hat<-predict(boost.fit,newdata = boost.test,n.trees = 100,type = "response")
y_hat1<-predict(boost.fit2,newdata = boost.test,n.trees = 100,type = "response")
misclass_boost<-sum(abs(y_hat-y_true))/length(y_true)
misclass_boost1<-sum(abs(y_ha1t-y_true))/length(y_true)
misclass_boost1<-sum(abs(y_hat1-y_true))/length(y_true)
misclass_boost
misclass_boost1
boost.fit<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.1,interaction.depth = 8,distribution = "adaboost")
boost.fit2<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.6,interaction.depth = 8,distribution = "adaboost")
y_hat<-predict(boost.fit,newdata = boost.test,n.trees = 100,type = "response")
y_hat1<-predict(boost.fit2,newdata = boost.test,n.trees = 100,type = "response")
misclass_boost<-sum(abs(y_hat-y_true))/length(y_true)
misclass_boost1<-sum(abs(y_hat1-y_true))/length(y_true)
misclass_boost
misclass_boost1
boost.fit2<-gbm(Outcome~.,data = boost.train,n.trees = 1000,shrinkage = 0.6,interaction.depth = 8,distribution = "adaboost")
y_hat1<-predict(boost.fit2,newdata = boost.test,n.trees = 100,type = "response")
misclass_boost1<-sum(abs(y_hat1-y_true))/length(y_true)
misclass_boost1
y_hat1<-predict(boost.fit2,newdata = boost.test,n.trees = 1000,type = "response")
misclass_boost1<-sum(abs(y_hat1-y_true))/length(y_true)
misclass_boost1
boost.fit<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.1,interaction.depth = 4,distribution = "adaboost")
boost.fit2<-gbm(Outcome~.,data = boost.train,n.trees = 1000,shrinkage = 0.6,interaction.depth = 4,distribution = "adaboost")
y_hat<-predict(boost.fit,newdata = boost.test,n.trees = 100,type = "response")
y_hat1<-predict(boost.fit2,newdata = boost.test,n.trees = 1000,type = "response")
misclass_boost<-sum(abs(y_hat-y_true))/length(y_true)
misclass_boost1<-sum(abs(y_hat1-y_true))/length(y_true)
misclass_boost
misclass_boost1
boost.fit<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.1,interaction.depth = 4,distribution = "adaboost")
,data = boost.train,n.trees = 100,shrinkage = 0.1,interaction.depth = 4,distribution = "adaboost")
boost.fit<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.1,interaction.depth = 4,distribution = "adaboost")
boost.fit2<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.6,interaction.depth = 4,distribution = "adaboost")
y_hat<-predict(boost.fit,newdata = boost.test,n.trees = 100,type = "response")
y_hat1<-predict(boost.fit2,newdata = boost.test,n.trees = 100,type = "response")
misclass_boost<-sum(abs(y_hat-y_true))/length(y_true)
misclass_boost1<-sum(abs(y_hat1-y_true))/length(y_true)
misclass_boost
misclass_boost1
boost.fit<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.1,interaction.depth = 6,distribution = "adaboost")
boost.fit2<-gbm(Outcome~.,data = boost.train,n.trees = 100,shrinkage = 0.6,interaction.depth = 6,distribution = "adaboost")
y_hat<-predict(boost.fit,newdata = boost.test,n.trees = 100,type = "response")
y_hat1<-predict(boost.fit2,newdata = boost.test,n.trees = 100,type = "response")
misclass_boost<-sum(abs(y_hat-y_true))/length(y_true)
misclass_boost1<-sum(abs(y_hat1-y_true))/length(y_true)
misclass_boost
misclass_boost1
x11()
varImpPlot(rf.fit)
importance(rf.fit)
x11()
varImpPlot(bag.fit)
importance(bag.fit)
x11()
varImpPlot(rf.fit)
importance(rf.fit)
x11()
varImpPlot(bag.fit)
importance(bag.fit)
summary(log.fit)
summary(log.fit)
test_err_log
