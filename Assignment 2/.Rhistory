plot(cv_ridge)
summary(cv_ridge)
cv_ridge$lambda.min
ridge_pred<-predict(ridge.fit,newx = test_matrix,s=cv_ridge$lambda.min,type = 'response')
ridge_error<-mean((ridge_pred-test_withpred$V86)^2)
lasso_error<-mean((lasso_pred-test_withpred$V86)^2)
cv_lasso<-cv.glmnet(train_matrix,traindata$V86,alpha=1)
plot(cv_lasso)
summary(cv_lasso)
cv_lasso$lambda.min
lasso_pred<-predict(cv_lasso,test_matrix,s=cv_lasso$lambda.min)
## LASSO Regression
lasso.fit<-glmnet(train_matrix,traindata$V86,alpha=1)
cv_lasso<-cv.glmnet(train_matrix,traindata$V86,alpha=1)
plot(cv_lasso)
summary(cv_lasso)
cv_lasso$lambda.min
lasso_pred<-predict(cv_lasso,test_matrix,s=cv_lasso$lambda.min)
lasso_error<-mean((lasso_pred-test_withpred$V86)^2)
lasso_error
setwd('C:/Users/Jaideep/Desktop/UB Data Science/Sem 1/R.Hageman/Homework 2')
traindata = read.table("ticdata2000.txt", sep="\t")
testdata = read.table("ticeval2000.txt", sep="\t")
test_tarvar = read.table("tictgts2000.txt", sep="\t")
lm_model<-lm(V86~.,data=traindata)
lm_predictions<-predict(lm_model,testdata)
lm_error<-mean((lm_predictions-test_tarvar$V1)^2)
colnames(test_tarvar)<-"V86"
test_withpred<-cbind(testdata,test_tarvar)
train_matrix<-model.matrix(V86~.,data = traindata)
test_matrix<-model.matrix(V86~.,data = test_withpred)
hist(traindata$V86)
hist(as.factor(traindata$V86))
hist(as.factor(traindata$V86))
hist(traindata$V86)
# generating data by creating instances of each variable from normal distribution of 1000
set.seed(28)
mydata<-data.frame(rnorm(1000))
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
epsilon<-rnorm(1)
beta<-rnorm(20)    ####### generating variable coefficients
beta[sample(1:20,5)]<-0
Y<-c()
for (i in seq(1000)) {
X <- 0
for (j in seq(20)) {
X<-mydata[i,j]*beta[j]+X
}
Y[i]<-X+epsilon
}
mydata_with_y<-cbind(mydata,Y)
library(caret)
datasplit<-createDataPartition(mydata_with_y$Y,p=0.9,list = F)
traindata<-mydata_with_y[datasplit,]
testdata<-mydata_with_y[-datasplit,]
best_subset<-regsubsets(Y~.,data = traindata,nvmax = 20)
best_summary<-summary(best_subset)
names(best_summary)
which(best_summary$cp==min(best_summary$cp))
which(best_summary$bic==min(best_summary$bic))
train_matrix<-model.matrix(Y~.,data = traindata)
test_matrix<-model.matrix(Y~.,data = testdata)
train_mse<-c()
for (i in seq(20)) {
pred_y<-train_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
train_mse[i]<-mean((pred_y-traindata$Y)^2)
}
plot(train_mse,type='b')
which(train_mse==min(train_mse))
test_mse<-c()
for (i in seq(20)) {
pred_y<-test_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
test_mse[i]<-mean((pred_y-testdata$Y)^2)
}
plot(test_mse,type='b')
which(test_mse==min(test_mse))
train_mse
test_mse
epsilon<-rnorm(1000)     ### given we are
# generating data by creating instances of each variable from normal distribution of 1000
set.seed(28)
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
mydata<-data.frame(rnorm(1000))
epsilon<-rnorm(1000)     ### given we are
# generating data by creating instances of each variable from normal distribution of 1000
set.seed(28)
mydata<-data.frame(rnorm(1000))
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
epsilon<-rnorm(1000)     ### given we are
beta<-rnorm(20)    ####### generating variable coefficients Beta
beta[sample(1:20,5)]<-0
Y<-c()   ### an empty vector is created to hold the target variable
for (i in seq(1000)) {
X <- 0
for (j in seq(20)) {
X<-mydata[i,j]*beta[j]+X          ##### generating the target variable
}
Y[i]<-X+epsilon[i]
}
mydata_with_y<-cbind(mydata,Y)
library(caret)
datasplit<-createDataPartition(mydata_with_y$Y,p=0.9,list = F)
traindata<-mydata_with_y[datasplit,]
testdata<-mydata_with_y[-datasplit,]
best_subset<-regsubsets(Y~.,data = traindata,nvmax = 20)
best_summary<-summary(best_subset)
names(best_summary)
which(best_summary$cp==min(best_summary$cp))
which(best_summary$bic==min(best_summary$bic))
train_matrix<-model.matrix(Y~.,data = traindata)
test_matrix<-model.matrix(Y~.,data = testdata)
train_mse<-c()
for (i in seq(20)) {
pred_y<-train_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
train_mse[i]<-mean((pred_y-traindata$Y)^2)
}
plot(train_mse,type='b')
test_mse<-c()
for (i in seq(20)) {
pred_y<-test_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
test_mse[i]<-mean((pred_y-testdata$Y)^2)
}
plot(test_mse,type='b')
which(test_mse==min(test_mse))
train_mse
test_mse
set.seed(28)
mydata<-data.frame(rnorm(1000))
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
epsilon<-rnorm(1000)     ### epsilon is not fixed constant to induce randomness in the data otherwise
### train and test will behave the same
beta<-rnorm(20)    ####### generating variable coefficients Beta
beta[sample(1:20,5)]<-0
Y<-c()   ### an empty vector is created to hold the target variable
for (i in seq(1000)) {
X <- 0
for (j in seq(20)) {
X<-mydata[i,j]*beta[j]+X          ##### generating the target variable
}
Y[i]<-X+epsilon[i]
}
mydata_with_y<-cbind(mydata,Y)
library(caret)
datasplit<-createDataPartition(mydata_with_y$Y,p=0.9,list = F)
traindata<-mydata_with_y[datasplit,]
testdata<-mydata_with_y[-datasplit,]
best_subset<-regsubsets(Y~.,data = traindata,nvmax = 20)
best_summary<-summary(best_subset)
names(best_summary)
which(best_summary$cp==min(best_summary$cp))
which(best_summary$bic==min(best_summary$bic))
train_matrix<-model.matrix(Y~.,data = traindata)
test_matrix<-model.matrix(Y~.,data = testdata)
train_mse<-c()
for (i in seq(20)) {
pred_y<-train_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
train_mse[i]<-mean((pred_y-traindata$Y)^2)
}
plot(train_mse,type='b')
test_mse<-c()
for (i in seq(20)) {
pred_y<-test_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
test_mse[i]<-mean((pred_y-testdata$Y)^2)
}
plot(test_mse,type='b')
which(test_mse==min(test_mse))
train_mse
test_mse
mydata<-data.frame(rnorm(1000))
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
epsilon<-rnorm(1000)     ### epsilon is not fixed constant to induce randomness in the data otherwise
### train and test will behave the same
beta<-rnorm(20)    ####### generating variable coefficients Beta
beta[sample(1:20,5)]<-0
Y<-c()   ### an empty vector is created to hold the target variable
for (i in seq(1000)) {
X <- 0
for (j in seq(20)) {
X<-mydata[i,j]*beta[j]+X          ##### generating the target variable
}
Y[i]<-X+epsilon[i]
}
mydata_with_y<-cbind(mydata,Y)
library(caret)
datasplit<-createDataPartition(mydata_with_y$Y,p=0.9,list = F)
traindata<-mydata_with_y[datasplit,]
testdata<-mydata_with_y[-datasplit,]
best_subset<-regsubsets(Y~.,data = traindata,nvmax = 20)
best_summary<-summary(best_subset)
names(best_summary)
which(best_summary$cp==min(best_summary$cp))
which(best_summary$bic==min(best_summary$bic))
train_matrix<-model.matrix(Y~.,data = traindata)
test_matrix<-model.matrix(Y~.,data = testdata)
train_mse<-c()
for (i in seq(20)) {
pred_y<-train_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
train_mse[i]<-mean((pred_y-traindata$Y)^2)
}
plot(train_mse,type='b')
test_mse<-c()
for (i in seq(20)) {
pred_y<-test_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
test_mse[i]<-mean((pred_y-testdata$Y)^2)
}
plot(test_mse,type='b')
which(test_mse==min(test_mse))
train_mse
test_mse
mydata<-data.frame(rnorm(1000))
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
epsilon<-rnorm(1000)     ### epsilon is not fixed constant to induce randomness in the data otherwise
### train and test will behave the same
beta<-rnorm(20)    ####### generating variable coefficients Beta
beta[sample(1:20,5)]<-0
Y<-c()   ### an empty vector is created to hold the target variable
for (i in seq(1000)) {
X <- 0
for (j in seq(20)) {
X<-mydata[i,j]*beta[j]+X          ##### generating the target variable
}
Y[i]<-X+epsilon[i]
}
mydata_with_y<-cbind(mydata,Y)
library(caret)
datasplit<-createDataPartition(mydata_with_y$Y,p=0.9,list = F)
traindata<-mydata_with_y[datasplit,]
testdata<-mydata_with_y[-datasplit,]
best_subset<-regsubsets(Y~.,data = traindata,nvmax = 20)
best_summary<-summary(best_subset)
names(best_summary)
which(best_summary$cp==min(best_summary$cp))
which(best_summary$bic==min(best_summary$bic))
train_matrix<-model.matrix(Y~.,data = traindata)
test_matrix<-model.matrix(Y~.,data = testdata)
train_mse<-c()
for (i in seq(20)) {
pred_y<-train_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
train_mse[i]<-mean((pred_y-traindata$Y)^2)
}
plot(train_mse,type='b')
test_mse<-c()
for (i in seq(20)) {
pred_y<-test_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
test_mse[i]<-mean((pred_y-testdata$Y)^2)
}
plot(test_mse,type='b')
which(test_mse==min(test_mse))
train_mse
test_mse
mydata<-data.frame(rnorm(1000))
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
epsilon<-rnorm(1000)     ### epsilon is not fixed constant to induce randomness in the data otherwise
### train and test will behave the same
beta<-rnorm(20)    ####### generating variable coefficients Beta
beta[sample(1:20,5)]<-0
Y<-c()   ### an empty vector is created to hold the target variable
for (i in seq(1000)) {
X <- 0
for (j in seq(20)) {
X<-mydata[i,j]*beta[j]+X          ##### generating the target variable
}
Y[i]<-X+epsilon[i]
}
mydata_with_y<-cbind(mydata,Y)
library(caret)
datasplit<-createDataPartition(mydata_with_y$Y,p=0.9,list = F)
traindata<-mydata_with_y[datasplit,]
testdata<-mydata_with_y[-datasplit,]
best_subset<-regsubsets(Y~.,data = traindata,nvmax = 20)
best_summary<-summary(best_subset)
names(best_summary)
which(best_summary$cp==min(best_summary$cp))
which(best_summary$bic==min(best_summary$bic))
train_matrix<-model.matrix(Y~.,data = traindata)
test_matrix<-model.matrix(Y~.,data = testdata)
train_mse<-c()
for (i in seq(20)) {
pred_y<-train_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
train_mse[i]<-mean((pred_y-traindata$Y)^2)
}
plot(train_mse,type='b')
test_mse<-c()
for (i in seq(20)) {
pred_y<-test_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
test_mse[i]<-mean((pred_y-testdata$Y)^2)
}
plot(test_mse,type='b')
which(test_mse==min(test_mse))
train_mse
test_mse
mydata<-data.frame(rnorm(1000))
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
epsilon<-rnorm(1000)     ### epsilon is not fixed constant to induce randomness in the data otherwise
### train and test will behave the same
beta<-rnorm(20)    ####### generating variable coefficients Beta
beta[sample(1:20,5)]<-0
Y<-c()   ### an empty vector is created to hold the target variable
for (i in seq(1000)) {
X <- 0
for (j in seq(20)) {
X<-mydata[i,j]*beta[j]+X          ##### generating the target variable
}
Y[i]<-X+epsilon[i]
}
mydata_with_y<-cbind(mydata,Y)
library(caret)
datasplit<-createDataPartition(mydata_with_y$Y,p=0.9,list = F)
traindata<-mydata_with_y[datasplit,]
testdata<-mydata_with_y[-datasplit,]
best_subset<-regsubsets(Y~.,data = traindata,nvmax = 20)
best_summary<-summary(best_subset)
names(best_summary)
which(best_summary$cp==min(best_summary$cp))
which(best_summary$bic==min(best_summary$bic))
train_matrix<-model.matrix(Y~.,data = traindata)
test_matrix<-model.matrix(Y~.,data = testdata)
train_mse<-c()
for (i in seq(20)) {
pred_y<-train_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
train_mse[i]<-mean((pred_y-traindata$Y)^2)
}
plot(train_mse,type='b')
test_mse<-c()
for (i in seq(20)) {
pred_y<-test_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
test_mse[i]<-mean((pred_y-testdata$Y)^2)
}
plot(test_mse,type='b')
which(test_mse==min(test_mse))
train_mse
test_mse
mydata<-data.frame(rnorm(1000))
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
epsilon<-rnorm(1000)     ### epsilon is not fixed constant to induce randomness in the data otherwise
### train and test will behave the same
beta<-rnorm(20)    ####### generating variable coefficients Beta
beta[sample(1:20,5)]<-0
Y<-c()   ### an empty vector is created to hold the target variable
for (i in seq(1000)) {
X <- 0
for (j in seq(20)) {
X<-mydata[i,j]*beta[j]+X          ##### generating the target variable
}
Y[i]<-X+epsilon[i]
}
mydata_with_y<-cbind(mydata,Y)
library(caret)
datasplit<-createDataPartition(mydata_with_y$Y,p=0.9,list = F)
traindata<-mydata_with_y[datasplit,]
testdata<-mydata_with_y[-datasplit,]
best_subset<-regsubsets(Y~.,data = traindata,nvmax = 20)
best_summary<-summary(best_subset)
names(best_summary)
which(best_summary$cp==min(best_summary$cp))
which(best_summary$bic==min(best_summary$bic))
train_matrix<-model.matrix(Y~.,data = traindata)
test_matrix<-model.matrix(Y~.,data = testdata)
train_mse<-c()
for (i in seq(20)) {
pred_y<-train_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
train_mse[i]<-mean((pred_y-traindata$Y)^2)
}
plot(train_mse,type='b')
test_mse<-c()
for (i in seq(20)) {
pred_y<-test_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
test_mse[i]<-mean((pred_y-testdata$Y)^2)
}
plot(test_mse,type='b')
which(test_mse==min(test_mse))
train_mse
test_mse
# generating data by creating instances of each variable from normal distribution of 1000
mydata<-data.frame(rnorm(1000))
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
epsilon<-rnorm(1000)     ### epsilon is not fixed constant to induce randomness in the data otherwise
### train and test will behave the same
beta<-rnorm(20)    ####### generating variable coefficients Beta
beta[sample(1:20,5)]<-0
Y<-c()   ### an empty vector is created to hold the target variable
for (i in seq(1000)) {
X <- 0
for (j in seq(20)) {
X<-mydata[i,j]*beta[j]+X          ##### generating the target variable
}
Y[i]<-X+epsilon[i]
}
mydata_with_y<-cbind(mydata,Y)
library(caret)
datasplit<-createDataPartition(mydata_with_y$Y,p=0.9,list = F)
traindata<-mydata_with_y[datasplit,]
testdata<-mydata_with_y[-datasplit,]
best_subset<-regsubsets(Y~.,data = traindata,nvmax = 20)
best_summary<-summary(best_subset)
names(best_summary)
which(best_summary$cp==min(best_summary$cp))
which(best_summary$bic==min(best_summary$bic))
train_matrix<-model.matrix(Y~.,data = traindata)
test_matrix<-model.matrix(Y~.,data = testdata)
train_mse<-c()
for (i in seq(20)) {
pred_y<-train_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
train_mse[i]<-mean((pred_y-traindata$Y)^2)
}
plot(train_mse,type='b')
test_mse<-c()
for (i in seq(20)) {
pred_y<-test_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
test_mse[i]<-mean((pred_y-testdata$Y)^2)
}
plot(test_mse,type='b')
which(test_mse==min(test_mse))
train_mse
test_mse
# generating data by creating instances of each variable from normal distribution of 1000
mydata<-data.frame(rnorm(1000))
for (i in seq(19)) {           # the for-loop creates 1000 random numbers from a normal distribution and
# does it for 20 variables
y<-data.frame(rnorm(1000))
mydata<-cbind(mydata,y)
}
colnames(mydata)<-paste("col",1:20,sep ="") # column names of the randomly created dataframe
epsilon<-rnorm(1000)     ### epsilon is not fixed constant to induce randomness in the data otherwise
### train and test will behave the same
beta<-rnorm(20)    ####### generating variable coefficients Beta
beta[sample(1:20,5)]<-0
Y<-c()   ### an empty vector is created to hold the target variable
for (i in seq(1000)) {
X <- 0
for (j in seq(20)) {
X<-mydata[i,j]*beta[j]+X          ##### generating the target variable
}
Y[i]<-X+epsilon[i]
}
mydata_with_y<-cbind(mydata,Y)
library(caret)
datasplit<-createDataPartition(mydata_with_y$Y,p=0.9,list = F)
traindata<-mydata_with_y[datasplit,]
testdata<-mydata_with_y[-datasplit,]
best_subset<-regsubsets(Y~.,data = traindata,nvmax = 20)
best_summary<-summary(best_subset)
names(best_summary)
which(best_summary$cp==min(best_summary$cp))
which(best_summary$bic==min(best_summary$bic))
train_matrix<-model.matrix(Y~.,data = traindata)
test_matrix<-model.matrix(Y~.,data = testdata)
train_mse<-c()
for (i in seq(20)) {
pred_y<-train_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
train_mse[i]<-mean((pred_y-traindata$Y)^2)
}
plot(train_mse,type='b')
test_mse<-c()
for (i in seq(20)) {
pred_y<-test_matrix[,names(coefficients(best_subset,i))]%*%coefficients(best_subset,i)
test_mse[i]<-mean((pred_y-testdata$Y)^2)
}
plot(test_mse,type='b')
which(test_mse==min(test_mse))
train_mse
test_mse
